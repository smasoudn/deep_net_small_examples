{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notMNIST Character Recognition using Tensorflow\n",
    "\n",
    "In this small project, we develope a simple neural network to detect characters in [nonMNIST](http://yaroslavvb.blogspot.ca/2011/09/notmnist-dataset.html) dataset using *Tensorflow*. \n",
    "\n",
    "The original example has been presented by [Udacity](https://www.udacity.com/).\n",
    "\n",
    "**Input:**\n",
    "- A set of nonMNIST character images from letter A to J\n",
    "\n",
    "**Goal:**\n",
    "- Prediction of a sample nonMNIST image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and uncompressed the nonMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    :param url: URL to file\n",
    "    :param file: Local file path\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "\n",
    "# Download the training and test dataset.\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_train.zip', './data/notMNIST_train.zip')\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_test.zip', './data/notMNIST_test.zip')\n",
    "\n",
    "# Make sure the files aren't corrupted\n",
    "assert hashlib.md5(open('./data/notMNIST_train.zip', 'rb').read()).hexdigest() == 'c8673b3f28f489e9cdf3a3d74e2ac8fa',\\\n",
    "        'notMNIST_train.zip file is corrupted.  Remove the file and try again.'\n",
    "assert hashlib.md5(open('./data/notMNIST_test.zip', 'rb').read()).hexdigest() == '5d3c7e653e63471c88df796156a9dfa9',\\\n",
    "        'notMNIST_test.zip file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210001/210001 [00:28<00:00, 7455.90files/s]\n",
      "100%|██████████| 10001/10001 [00:01<00:00, 7821.36files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features and labels uncompressed.\n"
     ]
    }
   ],
   "source": [
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from a zip file\n",
    "    :param file: The zip file to extract the data from\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        # Progress Bar\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
    "        \n",
    "        # Get features and labels from all files\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    # Load image data as 1 dimensional array\n",
    "                    # We're using float32 to save on memory space\n",
    "                    feature = np.array(image, dtype=np.float32).flatten()\n",
    "\n",
    "                # Get the the letter from the filename.  This is the letter of the image.\n",
    "                label = os.path.split(filename)[1][0]\n",
    "\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "train_features, train_labels = uncompress_features_labels('./data/notMNIST_train.zip')\n",
    "test_features, test_labels = uncompress_features_labels('./data/notMNIST_test.zip')\n",
    "\n",
    "# Limit the amount of data to work with a docker container\n",
    "docker_size_limit = 150000\n",
    "train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)\n",
    "\n",
    "# Set flags for feature engineering.  This will prevent you from skipping an important step.\n",
    "is_features_normal = False\n",
    "is_labels_encod = False\n",
    "\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation\n",
    "### Normalize image values\n",
    "For better convergence, we need to normalize images to be near zero (i.e. $\\mu = 0$ and $\\sigma = 1$). In face we normalize the values to be betweek 0.1 and 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalized\n"
     ]
    }
   ],
   "source": [
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    return 0.1 + ((image_data - 0) / (255 - 0) * 0.8) \n",
    "\n",
    "\n",
    "if not is_features_normal:\n",
    "    train_features = normalize_grayscale(train_features)\n",
    "    test_features = normalize_grayscale(test_features)\n",
    "    is_features_normal = True\n",
    "    print(\"Data normalized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels One-Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "if not is_labels_encod:\n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(train_labels)\n",
    "    train_labels = encoder.transform(train_labels)\n",
    "    test_labels = encoder.transform(test_labels)\n",
    "\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "    test_labels = test_labels.astype(np.float32)\n",
    "    is_labels_encod = True\n",
    "\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features and labels randomized and split.\n"
     ]
    }
   ],
   "source": [
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to pickle file...\n",
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data for easy access\n",
    "pickle_file = './data/notMNIST.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('./data/notMNIST.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': test_features,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint\n",
    "Let's load the all data we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and modules loaded.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = './data/notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    train_features = pickle_data['train_dataset']\n",
    "    train_labels = pickle_data['train_labels']\n",
    "    valid_features = pickle_data['valid_dataset']\n",
    "    valid_labels = pickle_data['valid_labels']\n",
    "    test_features = pickle_data['test_dataset']\n",
    "    test_labels = pickle_data['test_labels']\n",
    "    del pickle_data  # Free up memory\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim:  784\n"
     ]
    }
   ],
   "source": [
    "input_dim = train_features.shape[1]\n",
    "n_hidden_layer = 10\n",
    "n_classes = 10\n",
    "\n",
    "print(\"input dim: \", input_dim)\n",
    "\n",
    "\n",
    "features = tf.placeholder(tf.float32, shape=(None, input_dim))\n",
    "            \n",
    "labels = tf.placeholder(tf.float32, shape=(None,  n_classes))\n",
    "            \n",
    "weights = {'hidden_layer_1': tf.Variable(tf.truncated_normal((input_dim, n_hidden_layer))),\n",
    "           'out': tf.Variable(tf.Variable(tf.truncated_normal((n_hidden_layer, n_classes))))}\n",
    "\n",
    "\n",
    "biases = {\n",
    "    'hidden_layer_1': tf.Variable(tf.zeros(n_hidden_layer)),\n",
    "    'out': tf.Variable(tf.zeros(n_classes))}\n",
    "\n",
    "\n",
    "hidden_layer_1 = tf.add(tf.matmul(features, weights['hidden_layer_1']), biases['hidden_layer_1'])\n",
    "hidden_layer_1 = tf.nn.relu(hidden_layer_1)\n",
    "\n",
    "logits = tf.add(tf.matmul(hidden_layer_1, weights['out']), biases['out'])\n",
    "\n",
    "  \n",
    "# Cross entropy\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy function created.\n"
     ]
    }
   ],
   "source": [
    "# Feed dicts for training, validation, and test losssession\n",
    "train_feed_dict = {features: train_features, labels: train_labels}\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels}\n",
    "test_feed_dict = {features: test_features, labels: test_labels}\n",
    "\n",
    "    \n",
    "# Determine if the predictions are correct\n",
    "prediction = tf.nn.softmax(logits)\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "print('Accuracy function created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/100: 100%|██████████| 1114/1114 [00:02<00:00, 418.70batches/s]\n",
      "Epoch  2/100:   2%|▏         | 25/1114 [00:00<00:04, 249.16batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  0.252667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  2/100: 100%|██████████| 1114/1114 [00:02<00:00, 439.59batches/s]\n",
      "Epoch  3/100: 100%|██████████| 1114/1114 [00:02<00:00, 424.55batches/s]\n",
      "Epoch  4/100: 100%|██████████| 1114/1114 [00:02<00:00, 435.28batches/s]\n",
      "Epoch  5/100: 100%|██████████| 1114/1114 [00:02<00:00, 428.43batches/s]\n",
      "Epoch  6/100: 100%|██████████| 1114/1114 [00:02<00:00, 418.32batches/s]\n",
      "Epoch  7/100: 100%|██████████| 1114/1114 [00:02<00:00, 433.78batches/s]\n",
      "Epoch  8/100: 100%|██████████| 1114/1114 [00:02<00:00, 446.35batches/s]\n",
      "Epoch  9/100: 100%|██████████| 1114/1114 [00:02<00:00, 450.02batches/s]\n",
      "Epoch 10/100: 100%|██████████| 1114/1114 [00:02<00:00, 436.17batches/s]\n",
      "Epoch 11/100: 100%|██████████| 1114/1114 [00:02<00:00, 447.41batches/s]\n",
      "Epoch 12/100: 100%|██████████| 1114/1114 [00:02<00:00, 441.37batches/s]\n",
      "Epoch 13/100: 100%|██████████| 1114/1114 [00:02<00:00, 450.22batches/s]\n",
      "Epoch 14/100: 100%|██████████| 1114/1114 [00:02<00:00, 438.22batches/s]\n",
      "Epoch 15/100: 100%|██████████| 1114/1114 [00:02<00:00, 429.65batches/s]\n",
      "Epoch 16/100: 100%|██████████| 1114/1114 [00:02<00:00, 430.05batches/s]\n",
      "Epoch 17/100: 100%|██████████| 1114/1114 [00:02<00:00, 400.13batches/s]\n",
      "Epoch 18/100: 100%|██████████| 1114/1114 [00:02<00:00, 412.71batches/s]\n",
      "Epoch 19/100: 100%|██████████| 1114/1114 [00:02<00:00, 431.03batches/s]\n",
      "Epoch 20/100: 100%|██████████| 1114/1114 [00:03<00:00, 298.64batches/s]\n",
      "Epoch 21/100: 100%|██████████| 1114/1114 [00:02<00:00, 453.26batches/s]\n",
      "Epoch 22/100:   3%|▎         | 30/1114 [00:00<00:03, 299.92batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  0.578267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 1114/1114 [00:02<00:00, 447.54batches/s]\n",
      "Epoch 23/100: 100%|██████████| 1114/1114 [00:02<00:00, 452.07batches/s]\n",
      "Epoch 24/100: 100%|██████████| 1114/1114 [00:02<00:00, 446.82batches/s]\n",
      "Epoch 25/100: 100%|██████████| 1114/1114 [00:03<00:00, 352.63batches/s]\n",
      "Epoch 26/100: 100%|██████████| 1114/1114 [00:02<00:00, 417.76batches/s]\n",
      "Epoch 27/100: 100%|██████████| 1114/1114 [00:02<00:00, 395.53batches/s]\n",
      "Epoch 28/100: 100%|██████████| 1114/1114 [00:02<00:00, 444.09batches/s]\n",
      "Epoch 29/100: 100%|██████████| 1114/1114 [00:02<00:00, 446.61batches/s]\n",
      "Epoch 30/100: 100%|██████████| 1114/1114 [00:02<00:00, 438.55batches/s]\n",
      "Epoch 31/100: 100%|██████████| 1114/1114 [00:02<00:00, 443.12batches/s]\n",
      "Epoch 32/100: 100%|██████████| 1114/1114 [00:02<00:00, 443.69batches/s]\n",
      "Epoch 33/100: 100%|██████████| 1114/1114 [00:02<00:00, 443.78batches/s]\n",
      "Epoch 34/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.79batches/s]\n",
      "Epoch 35/100: 100%|██████████| 1114/1114 [00:02<00:00, 440.89batches/s]\n",
      "Epoch 36/100: 100%|██████████| 1114/1114 [00:02<00:00, 438.22batches/s]\n",
      "Epoch 37/100: 100%|██████████| 1114/1114 [00:02<00:00, 440.43batches/s]\n",
      "Epoch 38/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.03batches/s]\n",
      "Epoch 39/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.22batches/s]\n",
      "Epoch 40/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.08batches/s]\n",
      "Epoch 41/100: 100%|██████████| 1114/1114 [00:02<00:00, 422.32batches/s]\n",
      "Epoch 42/100:   3%|▎         | 37/1114 [00:00<00:02, 368.17batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  0.6436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 1114/1114 [00:02<00:00, 427.93batches/s]\n",
      "Epoch 43/100: 100%|██████████| 1114/1114 [00:02<00:00, 440.68batches/s]\n",
      "Epoch 44/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.84batches/s]\n",
      "Epoch 45/100: 100%|██████████| 1114/1114 [00:02<00:00, 435.20batches/s]\n",
      "Epoch 46/100: 100%|██████████| 1114/1114 [00:02<00:00, 448.98batches/s]\n",
      "Epoch 47/100: 100%|██████████| 1114/1114 [00:02<00:00, 441.08batches/s]\n",
      "Epoch 48/100: 100%|██████████| 1114/1114 [00:02<00:00, 446.45batches/s]\n",
      "Epoch 49/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.12batches/s]\n",
      "Epoch 50/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.94batches/s]\n",
      "Epoch 51/100: 100%|██████████| 1114/1114 [00:02<00:00, 446.10batches/s]\n",
      "Epoch 52/100: 100%|██████████| 1114/1114 [00:02<00:00, 438.32batches/s]\n",
      "Epoch 53/100: 100%|██████████| 1114/1114 [00:02<00:00, 443.92batches/s]\n",
      "Epoch 54/100: 100%|██████████| 1114/1114 [00:02<00:00, 446.53batches/s]\n",
      "Epoch 55/100: 100%|██████████| 1114/1114 [00:02<00:00, 439.47batches/s]\n",
      "Epoch 56/100: 100%|██████████| 1114/1114 [00:02<00:00, 435.98batches/s]\n",
      "Epoch 57/100: 100%|██████████| 1114/1114 [00:02<00:00, 441.50batches/s]\n",
      "Epoch 58/100: 100%|██████████| 1114/1114 [00:02<00:00, 444.00batches/s]\n",
      "Epoch 59/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.81batches/s]\n",
      "Epoch 60/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.36batches/s]\n",
      "Epoch 61/100: 100%|██████████| 1114/1114 [00:02<00:00, 441.48batches/s]\n",
      "Epoch 62/100:   3%|▎         | 36/1114 [00:00<00:02, 359.43batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  0.669333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 1114/1114 [00:02<00:00, 441.41batches/s]\n",
      "Epoch 63/100: 100%|██████████| 1114/1114 [00:02<00:00, 440.75batches/s]\n",
      "Epoch 64/100: 100%|██████████| 1114/1114 [00:02<00:00, 440.43batches/s]\n",
      "Epoch 65/100: 100%|██████████| 1114/1114 [00:02<00:00, 443.84batches/s]\n",
      "Epoch 66/100: 100%|██████████| 1114/1114 [00:02<00:00, 444.88batches/s]\n",
      "Epoch 67/100: 100%|██████████| 1114/1114 [00:02<00:00, 430.97batches/s]\n",
      "Epoch 68/100: 100%|██████████| 1114/1114 [00:02<00:00, 443.45batches/s]\n",
      "Epoch 69/100: 100%|██████████| 1114/1114 [00:02<00:00, 443.86batches/s]\n",
      "Epoch 70/100: 100%|██████████| 1114/1114 [00:02<00:00, 440.07batches/s]\n",
      "Epoch 71/100: 100%|██████████| 1114/1114 [00:02<00:00, 447.04batches/s]\n",
      "Epoch 72/100: 100%|██████████| 1114/1114 [00:02<00:00, 443.75batches/s]\n",
      "Epoch 73/100: 100%|██████████| 1114/1114 [00:02<00:00, 441.91batches/s]\n",
      "Epoch 74/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.05batches/s]\n",
      "Epoch 75/100: 100%|██████████| 1114/1114 [00:02<00:00, 443.58batches/s]\n",
      "Epoch 76/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.60batches/s]\n",
      "Epoch 77/100: 100%|██████████| 1114/1114 [00:02<00:00, 442.99batches/s]\n",
      "Epoch 78/100: 100%|██████████| 1114/1114 [00:02<00:00, 444.25batches/s]\n",
      "Epoch 79/100: 100%|██████████| 1114/1114 [00:02<00:00, 456.14batches/s]\n",
      "Epoch 80/100: 100%|██████████| 1114/1114 [00:02<00:00, 457.10batches/s]\n",
      "Epoch 81/100: 100%|██████████| 1114/1114 [00:02<00:00, 450.04batches/s]\n",
      "Epoch 82/100:   3%|▎         | 34/1114 [00:00<00:03, 338.22batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  0.726133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 1114/1114 [00:02<00:00, 455.73batches/s]\n",
      "Epoch 83/100: 100%|██████████| 1114/1114 [00:02<00:00, 455.64batches/s]\n",
      "Epoch 84/100: 100%|██████████| 1114/1114 [00:02<00:00, 453.31batches/s]\n",
      "Epoch 85/100: 100%|██████████| 1114/1114 [00:02<00:00, 455.83batches/s]\n",
      "Epoch 86/100: 100%|██████████| 1114/1114 [00:02<00:00, 459.78batches/s]\n",
      "Epoch 87/100: 100%|██████████| 1114/1114 [00:02<00:00, 453.22batches/s]\n",
      "Epoch 88/100: 100%|██████████| 1114/1114 [00:02<00:00, 456.54batches/s]\n",
      "Epoch 89/100: 100%|██████████| 1114/1114 [00:02<00:00, 455.93batches/s]\n",
      "Epoch 90/100: 100%|██████████| 1114/1114 [00:02<00:00, 455.82batches/s]\n",
      "Epoch 91/100: 100%|██████████| 1114/1114 [00:02<00:00, 458.61batches/s]\n",
      "Epoch 92/100: 100%|██████████| 1114/1114 [00:02<00:00, 452.49batches/s]\n",
      "Epoch 93/100: 100%|██████████| 1114/1114 [00:02<00:00, 453.45batches/s]\n",
      "Epoch 94/100: 100%|██████████| 1114/1114 [00:02<00:00, 451.42batches/s]\n",
      "Epoch 95/100: 100%|██████████| 1114/1114 [00:02<00:00, 447.86batches/s]\n",
      "Epoch 96/100: 100%|██████████| 1114/1114 [00:02<00:00, 458.40batches/s]\n",
      "Epoch 97/100: 100%|██████████| 1114/1114 [00:02<00:00, 454.27batches/s]\n",
      "Epoch 98/100: 100%|██████████| 1114/1114 [00:02<00:00, 462.25batches/s]\n",
      "Epoch 99/100: 100%|██████████| 1114/1114 [00:02<00:00, 459.45batches/s]\n",
      "Epoch 100/100: 100%|██████████| 1114/1114 [00:02<00:00, 456.13batches/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8FdXd+PHPNwuEhJ2wIwQVhYCskU0EBEG0FlxQURTc\nSrXVan20xdq69Xl+1dbHulZFBHcirvAoqAhYobJG9jUBAmSBkITs602+vz9muCRISIBL7iX5vl+v\n+8qcM2dmzjlZvpmZM2dEVTHGGGMCTZC/K2CMMcYcjwUoY4wxAckClDHGmIBkAcoYY0xAsgBljDEm\nIFmAMsYYE5AsQBljjAlIFqCM8TERSRSRy/1dD2POdhagjDHGBCQLUMbUEhH5lYgkiEimiMwXkQ5u\nvojIP0UkTURyRGSTiPRy110lIltFJFdEkkXkYf+2wpjaYwHKmFogIqOAvwE3Au2BvUCsu3osMBy4\nAGjmlslw170F/FpVmwC9gCW1WG1j/CrE3xUwpp6YDMxS1Z8ARORR4LCIRAGlQBOgO7BaVbdV2K4U\niBaRDap6GDhcq7U2xo/sDMqY2tEB56wJAFXNwzlL6qiqS4BXgFeBNBGZISJN3aLXA1cBe0Xk3yIy\npJbrbYzfWIAypnakAF2OJEQkAmgFJAOo6kuqOgCIxrnU94ibv0ZVJwBtgC+AubVcb2P8xgKUMWdG\nqIiEHfkAc4A7RKSviDQE/h+wSlUTReRiERkkIqFAPlAElItIAxGZLCLNVLUUyAHK/dYiY2qZBShj\nzowFQGGFz0jgL8CnQCpwHjDJLdsUeBPn/tJenEt//3DX3QYkikgOcA/OvSxj6gWxFxYaY4wJRHYG\nZYwxJiBZgDLGGBOQLEAZY4wJSBagjDHGBKSAnEkiMjJSo6Ki/F0NY4wxZ0BcXFy6qraurlxABqio\nqCjWrl3r72oYY4w5A0Rkb/Wl7BKfMcaYABWQAUqxZ7OMMaa+C8gAlVWU5e8qGGOM8bOADFDGGGOM\nTwOUiDQXkU9EZLuIbBORISLSUkQWiUi8+7WFL49pjDGmbvL1GdSLwNeq2h3oA2wDpgOLVbUbsNhN\nn5jdgjLGmHrPZwFKRJrhvLb6LQBVLVHVLGAC8I5b7B3gGl8d0xhjTN3lyzOorsAhYLaIrBORme5L\n2dqqaqpb5gDQ9ngbi8g0EVkrImtzcnN8WC1jjDFnI18GqBCgP/CaqvbDefFapct56rzb47gX8FR1\nhqrGqGpM0yZNj1fEGGNMPeLLAJUEJKnqKjf9CU7AOigi7QHcr2k+PKYxxpg6ymcBSlUPAPtF5EI3\nazSwFZgPTHXzpgLzqt2XjZIwxph6z9dz8d0PfCAiDYDdwB04QXCuiNyF8zrrG318TGOMMXWQTwOU\nqq4HYo6zarQvj2OMMabus5kkjDHGBCQLUMYYYwKSBShjjDEByQKUMcaYgGQByhhjTECyAGWMMSYg\nBWSAsgd1jTHGBGSAMsYYYyxAGWOMCUgWoIwxxgSkwAxQdgvKGGPqvcAMUMYYY+o9C1DGGGMCUkAG\nKBtmbowxJiADlDHGGGMByhhjTECyAGWMMSYgWYAyxhgTkCxAGWOMCUg+DVAiEiwi60TkSzfdUkQW\niUi8+7WFL49njDGm7vL1GdQDwLYK6enAYlXtBix208YYY0y1fBagRKQT8AtgZoXsCcA77vI7wDW+\nOp4xxpi6zZdnUC8AfwDKK+S1VdVUd/kA0LaqjUVkmoisFZG1ubm5PqyWMcaYs5FPApSIXA2kqWpc\nVWVUVTnBNLCqOkNVY1Q1pnGTxr6oljHGmLNYiI/2cwkwXkSuAsKApiLyPnBQRNqraqqItAfSfHQ8\nY4wxdZxPzqBU9VFV7aSqUcAkYImq3grMB6a6xaYC83xxPGOMMXXfmX4O6hlgjIjEA5e7aWOMMaZa\nvrrE56Wq3wPfu8sZwGhfH8MYY0zdF5gzSdjbNowxpt4LzABljDGm3rMAZYwxJiAFZICyN+oaY4wJ\nyABljDHGWIAyxhgTkCxAGWOMCUgWoIwxxgQkC1DGGGMCkgUoY4wxAckClDHGmIBkAcoYY0xACsgA\nZQ/qGmOMCcgAZYwxxliAMsYYE5AsQBljjAlIFqCMMcYEpMAMUDZGwhhj6j2fBSgROUdElorIVhHZ\nIiIPuPktRWSRiMS7X1v46pjGGGPqLl+eQXmA/1LVaGAw8FsRiQamA4tVtRuw2E0bY4wxJ+SzAKWq\nqar6k7ucC2wDOgITgHfcYu8A1/jqmMYYY+quM3IPSkSigH7AKqCtqqa6qw4AbavYZpqIrBWRtXn5\neWeiWsYYY84iPg9QItIY+BR4UFVzKq5TVaWKIRCqOkNVY1Q1JiIiwtfVMsYYc5bxaYASkVCc4PSB\nqn7mZh8Ukfbu+vZAmi+PaYwxpm7y5Sg+Ad4Ctqnq8xVWzQemustTgXm+OqYxxpi6K8SH+7oEuA3Y\nJCLr3bw/Ac8Ac0XkLmAvcKMPj2mMMaaO8lmAUtXlgFSxerSvjmOMMaZ+CMyZJIwxxtR7FqCMMcYE\nJAtQxhhjAlJABih7o64xxpiADFDGGGOMBShjjDEByQKUMcaYgGQByhhjTEAKzABlYySMMabeC8gA\nZaP4jDHGBGaAUgtQxhhT3wVkgCqn3N9VMMYY42cBGaDsDMoYY4wFKGOMMQEpMAOUDZIwxph6LyAD\nVJmW+bsKxhhj/CwgA1RpWam/q2CMMcbPAjJA5Zfks3j3Yn9XwxhjjB/57JXvvnb5e5f/LK9T004k\n5SQBEN06muScZKJbRyMiNAxuSFZRFld1u4oiTxF5JXk0CG7AuPPHcSj/EPGZ8XRp1oWRUSNJzEpk\nf85+oltHc07Tc8gqyqKkrISo5lHkFOfQKLQRgtAqvBXpBelEhkdSUlZCSFAIJWUlhIeGU67llJWX\nESRBBAcFA1BWXuZdBmewh4jUTocZY0wdI7UxYk5ExgEvAsHATFV95kTlm53bTHOm5hDVPIrErMQz\nXj9jTGWhQaGUltfsUvuxZUdGjeT7xO+96VFdR7FkzxJvuk1EG9Ly0wDnn86soizySvIA6NWmF7sP\n76agtACA3m17szdrL9nF2TQKacR5Lc8jLT+NtPw0urXsRsOQhqTkppBZmMmlnS8lvSCdlNwUsouz\nGXveWJJykkjJTaFRSCOiW0eTXpBOfGY8PSJ70DysOYeLDrPp4CbGnDeGgtICDuUfIikniXHnjyM1\nL5X0gnQ85R76tevHoQJnXbvG7WgT0Yac4hy2p28npkMMANlF2cRnxjPm3DGkF6STUZhBdlE2wzoP\nIyknicNFhwkLCaNz085kF2eTmJVIt1bdaBTSiJziHHZk7GB45+HkluRyuOgwB/IOMKLLCJJzk8kp\nzqGsvIwekT04VHCItPw02jZuS9MGTckrzWNX5i76teuHp9xDbkkuuw/vZlTXUaTmppJdnE1BaQEx\nHWLYn7Pf+Sc8pBHtG7cnpziHpNwkoppFER4aTnZxNrsO72Jgh4EUlxV72zGww0AOFRwiqygLRTmv\nxXlkFmZyqOAQbcLb0LhBY/JK8kjMTqRX614oSk5xDnuz9zKk0xCyirLIKMygpKyE0V1Hc1f/u+JU\nNaa6n60zHqBEJBjYCYwBkoA1wM2qurWqbWJiYnTt2rXedMUzkczCTA7kHSBYgskpzmFtylr2Zu/l\n3BbnsufwHjalbSI5N5k+bfuwOnk1hZ5C0vLTaNe4HbsP70YQGyVojDH+9CQ1ClC1cYlvIJCgqrsB\nRCQWmABUGaCOVfEyWctGLWnZqKU3fXHHi31W0ZNVMXAeudwnIqgqhZ5CwkLCCJIgysrLyC7OpmWj\nlpSVOyMU0wvSadu4LSVlJZSVl5FXkkfriNYUlhaSV5JHw5CGNG3YlILSAlJzU+ncrDOhwaEUe4qJ\nz4ynZ+uelGs5BaUFpOSmcEGrCyguKyarKIvSslI6Ne1EkaeIfdn7aNe4HU0bNqXIU8SmtE30b9+f\nIAkivySfbenbiOkQQ0lZCTnFORzKP0R062gKPYUk5STRKKQRHZt2pLC0kE1pm+jZuicRDSLIL8ln\nTcoahnUeBjj/Pe7M2MmQc4ZQWFrIwfyDFJQW0COyBwWlBezI2EH7xu1p17gdBaUFrEhaweBOg4kI\njSCrKIs1KWsY1XUUpWWlZBRmkJyTTEyHGIo8Rew6vIuGwQ05v+X5FJQWEJcaR4/IHkSGR5JXkscP\ne39gVNdRhASFkFGYwZa0LYyIGkFJWQlJOUnkFufSp10fijxFbE7bTJuINnRp1oWC0gL+vfffDOk0\nxPvf9I/7f2TMuWNQlAN5B9iXvY8hnYbgKfewPX07IUEh9GjdgyJPESv2r6B7ZHc6NOlAXkkei/cs\nZlTXUYSHhnMw7yCb0jYxMmokALsyd5FRmMGgjoMo0zLWpqylVaNWXNDqAoo8RSzavYjBnQbTJqIN\nGQUZLE1cypXnX0mD4Absy97H9vTtjD53NIKw7sA6POUeLu5wMSVlJSxNXMp5Lc6jc7POFJQW8HXC\n14yMGknThk1Jy09jdfJqxp43liAJIiEzgdS8VIZ3GU5+ST6b0zbTKLQRvdv2Jqsoi+X7ltO7bW/a\nNW5HRkEGK5JWMDJqJEESRFJOEnuz9jIiagT5JfnsPrybIk8Rfdv1paC0gDUpa+jYpCMXtb2IrYe2\nsjZlLUM6DaFNRBtWJK1g9+HdDOs8jNziXDanbSa7OJtLzrmE7OJsftz/I83DmtOrTS+yirL4PvF7\n+rTtQ9vGbdmbtZdNaZsY3mU4grAzcycH8g4wvPNwCkoLWH9wPUESREz7GPJL81m2bxldmnUhqnkU\nGYUZrElew8UdLyYiNILErER2H97NpV0upay8jG3p28guyubSLpdSUlbCf/b9h2ZhzYhuHe307Z6l\n9Gjdgw5NOpCWn0ZcShyXdrmUBsEN2JW5i7T8NO/P2qqkVTRu0JhebXoBsCB+AdGto+nQpAP5pfn8\nuP9HBnUcRESDCJJyktiRvoNRXUehKJsObqLQU8jgToMJDQrlq/iviGoeRdfmXRERluxZQs/WPZ2f\nj8IMNh7cyNBzhhISFEJ8RjypeamM6DKC0OBQluxZQrOGzejZpicRoRF8s+sbujbvSocmHSguK2Zt\nylr6t+9Pp6adWJe6jv05+xnRZQQdm3bks22fUeQpYtz542ge1pzYzbG0iWjD8C7DScxKZG3KWrpH\ndqdP2z4s37ec5Nxkhp4zlHaN2zF/x3w85R5GdR1F04ZN+WL7FzQMbsgV519BVlEWP+z9gXOansMl\nnS8hltga/Y2tjTOoicA4Vb3bTd8GDFLV+44pNw2YBtC5c+cBe/fuPaP1MsYY4x8iUqMzqIAZxaeq\nM1Q1RlVjWrdu7e/qGGOM8bPaCFDJwDkV0p3cPGOMMaZKtXEPag3QTUS64gSmScAtVRV2L/Wli0h9\nv8YXCaT7uxIBwPrB+uAI6wdHXeiHLjUpdMYDlKp6ROQ+4BucYeazVHXLCTaZpqr1/hqfiKytyTXa\nus76wfrgCOsHR33qh1p5UFdVFwALauNYxhhj6oaAGSRhjDHGVBSIAWqGvysQIKwfHNYP1gdHWD84\n6k0/1MpUR8YYY8zJCsQzKGOMMcYClDHGmMAUUAFKRMaJyA4RSRCR6f6uz+kSkXNEZKmIbBWRLSLy\ngJvfUkQWiUi8+7VFhW0eddu/Q0SuqJA/QEQ2ueteEncSQBFpKCIfufmrRCSqtttZEyISLCLrRORL\nN10f+6C5iHwiIttFZJuIDKmn/fB79/dhs4jMEZGw+tAPIjJLRNJEZHOFvFppt4hMdY8RLyJTa6fF\nPqCqAfHBeUZqF3Au0ADYAET7u16n2ab2QH93uQnOrO7RwN+B6W7+dOBZdznabXdDoKvbH8HuutXA\nYECAhcCVbv5vgNfd5UnAR/5udxV98RDwIfClm66PffAOcLe73ABoXt/6AegI7AEauem5wO31oR+A\n4UB/YHOFvDPebqAlsNv92sJdbuHv/qhRn/m7AhW+UUOAbyqkHwUe9Xe9fNzGeTivHdkBtHfz2gM7\njtdmnIebh7hltlfIvxl4o2IZdzkE5wlz8Xdbj2l3J2AxMIqjAaq+9UEznD/Mckx+feuHjsB+949l\nCPAlMLa+9AMQReUAdcbbXbGMu+4NnFce+b0/qvsE0iW+Iz+4RyS5eXWCe7rdD1gFtFXVVHfVAaCt\nu1xVH3R0l4/Nr7SNqnqAbKCVzxtwel4A/gCUV8irb33QFTgEzHYvdc4UkQjqWT+oajLwHLAPSAWy\nVfVb6lk/VFAb7T5r/7YGUoCqs0SkMfAp8KCq5lRcp86/NHV2rL+IXA2kqWpcVWXqeh+4QnAu77ym\nqv2AfJxLOl71oR/ceywTcAJ2ByBCRG6tWKY+9MPx1Nd2n0ggBag6Oeu5iITiBKcPVPUzN/ugiLR3\n17cH0tz8qvog2V0+Nr/SNiISgnMpKcP3LTlllwDjRSQRiAVGicj71K8+AOe/1iRVXeWmP8EJWPWt\nHy4H9qjqIVUtBT4DhlL/+uGI2mj3Wfu3NZAClHfWcxFpgHOTb76f63Ra3NE1bwHbVPX5CqvmA0dG\n0kzFuTd1JH+SOxqnK9ANWO1eAsgRkcHuPqccs82RfU0Elrj/iQUEVX1UVTupahTO93SJqt5KPeoD\nAFU9AOwXkQvdrNE4b5WuV/2Ac2lvsIiEu/UfDWyj/vXDEbXR7m+AsSLSwj2DHevmBT5/3wSr+AGu\nwhnptgt4zN/18UF7huGcsm8E1rufq3CuCy8G4oHvgJYVtnnMbf8O3NE5bn4MsNld9wpHZwEJAz4G\nEnBG95zr73afoD9GcnSQRL3rA6AvsNb9efgCZ0RVfeyHp4DtbhvewxmpVuf7AZiDc9+tFOeM+q7a\najdwp5ufANzh776o6cemOjLGGBOQAukSnzHGGONlAcoYY0xAsgBljDEmIFmAMsYYE5AsQBljjAlI\nFqCMMcYEJAtQxhhjApIFKGOMMQHJApQxxpiAZAHKGGNMQLIAZYwxJiBZgDLGGBOQLEAZY4wJSBag\njKmGiHwvIodFpKG/62JMfWIBypgTEJEo4FKc93qNr8XjhtTWsYwJVBagjDmxKcBK4G2Ovq0UEWkk\nIv8rIntFJFtElotII3fdMBH5UUSyRGS/iNzu5n8vIndX2MftIrK8QlpF5LciEo/zAjtE5EV3Hzki\nEicil1YoHywifxKRXSKS664/R0ReFZH/rdgIEZkvIr8/Ex1kzJliAcqYE5sCfOB+rhCRtm7+c8AA\nYCjQEvgDUC4iXYCFwMtAa5y36K4/ieNdAwwCot30GncfLYEPgY9FJMxd9xBwM85bmpvivDW1AHgH\nuFlEggBEJBK43N3emLOGBShjqiAiw4AuwFxVjcN5xfYt7h/+O4EHVDVZVctU9UdVLQZuAb5T1Tmq\nWqqqGap6MgHqb6qaqaqFAKr6vrsPj6r+L87r0S90y94N/FlVd6hjg1t2NZANjHbLTQK+V9WDp9kl\nxtQqC1DGVG0q8K2qprvpD928SCAMJ2Ad65wq8mtqf8WEiDwsItvcy4hZQDP3+NUd6x3gVnf5VuC9\n06iTMX5hN2KNOQ73ftKNQLCIHHCzGwLNgfZAEXAesOGYTfcDA6vYbT4QXiHd7jhltEIdLsW5dDga\n2KKq5SJyGJAKxzoP2Hyc/bwPbBaRPkAP4Isq6mRMwLIzKGOO7xqgDOdeUF/30wNYhnNfahbwvIh0\ncAcrDHGHoX8AXC4iN4pIiIi0EpG+7j7XA9eJSLiInA/cVU0dmgAe4BAQIiKP49xrOmIm8FcR6SaO\n3iLSCkBVk3DuX70HfHrkkqExZxMLUMYc31RgtqruU9UDRz7AK8BkYDqwCScIZALPAkGqug9n0MJ/\nufnrgT7uPv8JlAAHcS7BfVBNHb4BvgZ2AntxztoqXgJ8HpgLfAvkAG8BjSqsfwe4CLu8Z85SoqrV\nlzLGnHVEZDjOpb4uar/o5ixkZ1DG1EEiEgo8AMy04GTOVtUGKBGZJSJpInK8G7G4175fEpEEEdko\nIv0rrBsnIjvcddN9WXFjzPGJSA8gC2cwxwt+ro4xp6wmZ1BvA+NOsP5KoJv7mQa8Bs5T7sCr7vpo\nnAcHo6vaiTHGN1R1m6pGqOpQVc3xd32MOVXVBihV/QHnZm9VJgDvug8KrgSai0h7nKG2Caq6W1VL\ngFi3rDHGGFMtXzwH1ZHKI4uS3Lzj5Q+qaiciMg3nDIyIiIgB3bt390HVjDHGBJq4uLh0VW1dXbmA\neVBXVWcAMwBiYmJ07dq1fq6RMcaYM0FE9taknC8CVDLOlCtHdHLzQqvIN8YYY6rli2Hm84Ep7mi+\nwUC2qqbiPMDYTUS6ikgDnAkr5/vgeMYYY+qBas+gRGQOMBKIFJEk4AmcsyNU9XVgAc6T8wk4U/3f\n4a7ziMh9OE/DBwOzVHXLGWiDMcaYOqjaAKWqN1ezXoHfVrFuAU4AM8YYY06KzSRhjDEmIFmAMsYY\nE5AsQBljjAlIFqCMMcYEJAtQxhhjApIFKGOMMQHJApQxxpiAZAHKGGNMQLIAZYwxJiBZgDLGGBOQ\nLEAZY4wJSBagjDHGBCQLUMYYYwKSBShjjDEByQKUMcaYgFSjACUi40Rkh4gkiMj046x/RETWu5/N\nIlImIi3ddYkissldt9bXDTDGGFM31eSNusHAq8AYIAlYIyLzVXXrkTKq+g/gH275XwK/V9XMCru5\nTFXTfVpzY4wxdVq1AQoYCCSo6m4AEYkFJgBbqyh/MzDHN9Uzxpg6RBVEQBX1lCEoZR7FU1BC/oFc\nmneMoDC7hJKkNPJzyghvGUZIaSHrf8ihZZNSQhuFUJJfyteLQ+nZOZfCkmCalGby8rI+TOqykrIm\nzclOK+bVjcO4OXIRrc9tStyeluzIbktnz24ubJNFfFlXEveH0DQol8jQHPaGdyclvQFNyKVFSC4H\nGnRha0EU57CPYMpIpCsADShGUIoJq7XuEueN7ScoIDIRGKeqd7vp24BBqnrfccqG45xlnX/kDEpE\n9gDZQBnwhqrOqOI404BpAJ07dx6wd+/eU26UMcZUSdWJEwcPQMOG6M54snOE/IwimhQcZP+GTBas\nbEH/HkUE/7SG79OiSU5vQNe2hbyXOppWZBBPN7qznZUMpoSG/m7RWUjiVDWmulI1OYM6Gb8E/nPM\n5b1hqposIm2ARSKyXVV/OHZDN3DNAIiJiTlx1DTG1A+ZmdC8OWW790KjRpR/uYDQJmHEby3l8LYD\n6Pf/pmHLCJaXD+Wb3ecTSikDiONpHj9B4BD3a3v366DjF1sDMOVoOrXy6jTannKzalvriHwO5Ud4\n0wM7H2D1vnYANG9YQLtmhWxPawXAPb/Yz+qfQvgp1emfebMy+NVvQ0krbArAjrW5XBjTBIAx3ffz\n91fC6Xe5s+3sJ/dyYZ8whl7r9M3ujXlsWprOhAeiACgpVlZ+vJ/ht9aw4qp6wg8wBPimQvpR4NEq\nyn4O3HKCfT0JPFzdMQcMGKDGmLqntFR1xQrVQ1sO6sd/+knfuuoT/Z28qKNZpM71r8D79I3cVyn9\nlwnrvctCmb75l73e9IMTduusP8V700k78nR416Pri4uP7ueRa+M1M/No+tsPD2lKytH04YwyXb8s\nR0F1yshEVVX9vzeSFVS/eueQqqrO+lO8XtA6Q/ftLFRV1b/ckqCTRh3Q0lLVsjLVB8fv0vf+laOq\nqrnZZfrnqXs1Kcn5XiTtzNcP/nlQ8/Kc9I64XF3+TZ6WlTnpuKXZmrKv1Pu927b26LqSEtWEhKPf\n15IS1YKCmv8cAGu1mjigTjdUG6BCgN1AV6ABsAHoeZxyzYBMIKJCXgTQpMLyjziXCy1AGVOPpO/M\n0IeHr6y1oPLIhB2V0iUllderHl1+8uo1WuYp96ZTNqXr97N2KaiGSZGqqr70m60Kqh/8eauqqv5q\nbKKCanJ8vqqqPnnTFp067oB6PM6+X/vtJl3wibOuqLBc33xiv+Y7Sc057NHtP+V7++bQIdX09Fr4\nJgQQnwUoZ19cBewEdgGPuXn3APdUKHM7EHvMdue6AW0DsOXIttV9LEAZUzvKypyzmpISVY/H+S+4\nvFw1OdnJ37rVyU/e59GyMtXdO0q0pKBUD+3M1Py0PI3/MU0zNydr/NcJGv/5Jo17cZkObLFDu0Sk\nnXaQuffqymcuWVlHl7uGJavq0fS7f9ysiWsPedMFOaU6809OkBncNVVVVX9/Y5KC6rofnDOKlx9M\n0Mdu2+s9K5j7/H7dtT7H2zfr15RoebmzXF6u3uBjTl9NA1S1gyT8ISYmRteutUemzNmnpARCQiDI\nfcKwoADCw51lLVcKs0sIb9EQSkooPZSFhxAatW5M7v4sEuMyiIxqTOKmXDKyQ8hNyaV3b4hbWcrh\nnCAa5GYSn96cvJIGpB5uhJSXsTypC52bZrMho5P/Gn0avn4lgXH3nQ/Am7f/h3bdm/PL6T0BKC+H\nWy6OJzauGw+O2sA/F/ehT1Q2G/c2I2lHPh0viGDqmBSat2nAix9EAvDxvw5x+Q0taNE6BFXYsQO6\nd/db80wVRGo2SMIClDnrHRsUspLyCGnemMaNoby0jOTVyRwoa033fo04tPkg2VuTKevYmWbnRZLy\n9UaWfi9cck1rDmQ2oMm6H3jlh97ceU8DtqzMJT9uO19lDWXc4Gz2xpfwf3t6AdC/WQItgnNZnNnP\nW4/zJYEEPd8fXXDWeP2u1WRnC3/85GKu6rier5L6MnlkEh/+uxNJCUV0ODeMV/+wl8HXdyRmcAi5\nOcr3S5VfTnC+uYWFUFQELVr4uSHmtNQ0QNXoEl9tf+wSX91TWqpaWHg0nbClSFMSi72XUOb+9w5d\n+FayFuZ5NDO5QH/RPUEfvX67Zh7y6D/vde4n/PfEdbr0pY3aOKRAQfWBURt1TNRO72WdC5ul1to9\njrr8OZeESulf8Ual9KLzfu1d7t1wm65+dok3/cbkf+t/vszwpp/8dbJu3eLc32kanOv9/sc+vUMz\nkk7irrqpU/DlPaja/liAClxlZeq9Zr9yUY6uW12iBQWqJcXl+vtxW/X1323R4gKPLpkRrx1DD+pD\nQ37UfWtezID8AAAdSklEQVQOaLuGmQqqv+3/o97de5Xf/wifLZ9BrKiUvoKF3uUlQx/TUIoVVP8Q\n9qJ6vjy6Lv+v/6u6ebM3rTt36r6/vq2gemWjpaplZfpxy2kKqiv/8Klqebnew78UVMtLnP8m7mSm\n3sq7zjc7L0+H8YPOHvCyqqom/uCMTFv+Upyqqs7/135tHFqouVnOjZr9GzJ0w1f7vT83u+M9euhg\nWW39mJoAZwHKnLTSUtUPX8/WRV971ONR/XdsivZsm6bTJ8Zrwo8HvWcuoDqu595T/qMbiJ8WZFRK\nv8R93uWrma9/5G/e9MzGD2gMq50/9nylKS9/4l33SvSrWpZ60Jte9of5mvTdNgXVJmRr8vLd+s/B\nsQqqD/T4RksKPTqeLxRU9/x7r6qqDmW59ma9lhUWq6rqL/g/fb/1g6qqWvjdcp3G65r65Ouqqrr/\n/mf1Kf6i5fudscM/RU/Wz5ng/Z7O52pd0+t2J5GdrZ9yrWb+zdlWExI0vc8oZxiZqpatidOiJ/92\n9Adi40bVDRuOpjMynHHSxpwmC1BGVZ2/J5mZqnl5zkik1/+8T8cPS9cvY3P02T9l+T0wVPdpy9HL\ndmP4xrs8lq/19YiHvOmnwv+m6U++7E2vG/+4Zn71o4LqtXyqxUv/o5/9YqaC6r8HPaJaVOQNOmUb\nNqmq6iQ+1Cv5SjU/X7W8XGNYra/wG1VVPfz+lzqANbrlhidUVXXTuIf1ej7W4nVbVFX184jJ+gRP\nePt9NlP12/ZTnERurn7M9Zr+zJuqqurZtlMXdLhLy1Oc0WUFy9Zq4v3PHf2mrVihunz50fR//qN6\n4MDR9E8/HT2N9XhU9x89U9HiYtXc3Mrp0qPPshgTCCxA1SOHDqn3Xs6WVbl646A9+tr/y9R57+f4\nJag0oMi7PIrv9HK+VVAdzI+6/byrvOveG/iSFn159AHNnA//T7WsTEG1J5tUDxzQ7S8sUFB9N+ZF\nVVX94oJHFFQzFqxUVdXPuEYf46/evvie4bqJnk4iM1O3c4EW3Xa3k16wQFNpq7rS2Vaff17LkaOd\n9+STqo88crRjn35addkyZ9njcdJZWU46J0f144+Plk1LU92+/Wg6K+vknlw0ph6xAFWHffaPBN24\nNF1LSlSn37irVoPPLbyvXzPWmz5w3b2qX3zhTevKlZqz3Xna/bcN31T1eHTDlOcUVHc+MkNVVd9v\n9Tu9kG1aXug8BLmI0Tqfq73t20p3zRx7o5PYv19zaKz67bdOetMm1QkTVIucbXXFCtW33z7aOStW\nqG7bdjS9ffvRsqrqfVrSGOM3FqDOYlmHy3X1Cudm87ofC7RleIEKZTr56jNzSe5h/q7Lwi73pktu\nvUNX/OZdBdXprd9UTU/XmT2fV1BN+myVqqr+K/R3eh2feOu8jj6665wRTqK4WFPCz9PSdz5w0mlp\nqhMnqh4+7KT37KkcVPbsUY2PP5o+fNjudRhTh9U0QNlzUH6SlARt2zrP78x5v4zn/pLFQ0+3YMYr\nJSxb49vp7C9iI6NZzHr68j2XkX/bPYRPmcj4MQWk0IG1eT0gIoJnZDpDe+YwfPO/4OBBlrS7mUu/\ne5LQ0cPRpGQ8/3yZ0L//DwQHOw1ITYWLL3YOkpfnNCas9qbiN8acnexB3QDz5pvQpg306wdff5LH\nr/+rsc+P8ThP8TRPMJgVzJy2hvCWYUx6pg9fvLiP9r+7gey/v8H2P85iUNkK56nWb7+F/Hy49lpn\nBykp0Lz50akPjDHmDLAA5WefzfWwcoVy9bWhvPJ0Bh8vbuXT/f+13atcdHUXnp7Znm7EE1t8HQQH\n803fPzDwiatoMXG0M1fM/PkwYYLzkjRjjAkAFqBq2fdLlVsnl/OLXwaTsyed2EWRp73Pgazi4rDN\nvFp0F1v/8RWNhvRl79xV/PRtOr/fNs0plJDgnPF06HDaxzPGmNpgAeoMKy2Fhx+Gl146vf30YhOb\nuYhfMp9Hr1hH+zuv5N6bMvjnrOZ0v2MI5fmF7I/9D13uutw3FTfGGD+zAHWGxMbCom+VWbNP/pLZ\nHCbhIYQmbcLJCm7F1OW/gmbNKFizhQYXRBFybuczUGNjjAksNQ1QNXrlu4iMA14EgoGZqvrMMetH\nAvOAPW7WZ6r6dE22PVtkZsLtE/P4v6WNOfrK6KpFkMfGi+8m/PwOtPrzvaR/tYr2j8Qet2z4uOE+\nrq0xxpz9qg1QIhIMvAqMAZKANSIyX1W3HlN0mapefYrbBqwvv4Rf/vJI6ucj74bzb0azmCLCmPJg\nK7pPuBAuuQQO5UCHowGpfXS32qmwMcbUETU5gxoIJKjqbgARiQUmADUJMqezrd89+yxMn/7z/Il8\nzEM8T/v/mkzUpMHQ608/f/7HBi0YY8xpqUmA6gjsr5BOAgYdp9xQEdkIJAMPq+qWk9gWEZkGTAPo\n3Nm/92LS0+Hum3KYt6Rppfx/cS/33h8KDz0EUSv8VDtjjKkfanQPqgZ+Ajqrap6IXAV8AZzUNS1V\nnQHMAGeQhI/qdVKKiuD2KWV89HEw4ASn+3mJv/BXWk++At57z54nMsaYWlKTAJUMnFMh3cnN81LV\nnArLC0TkXyISWZNtA8WWLdCrFzhjORxfMIEJi+6HESkQGuq3uhljTH0UVIMya4BuItJVRBoAk4D5\nFQuISDsR59RCRAa6+82oybb+Nn++c1LkBCfHBL4gi2ZM2PoMXH65BSdjjPGDas+gVNUjIvcB3+Cc\nXsxS1S0ico+7/nVgInCviHiAQmCSO2Ptcbc9Q22psfh4WLAAnnyinKzsyjFa77obnnoKOmb7qXbG\nGGOgnj2oW1h4/HlQ+xPH3czkhj47iVy/2OfHNcYYc5RPH9Q9mx06BB06KB7P8Qc3bKIXvRb8Ay79\nh70qwhhjAkidDlChIeV4yoKoauaHQaykl26u3UoZY4ypkZoMkjjr/Pa2bERwg1NlX9/wFlpcgmZk\nsjLdZncwxphAVafOoBa/n8rlt7UHmv1s3YTwRYws+ZYrPvq7M2yvZcvar6AxxpgaqxMBqrwcJl6S\nwucrfz690Mp3djBoyoU40wGOqfW6GVMflJaWkpSURFFRkb+rYgJIWFgYnTp1IvQUH9U56wOUx3Pk\nMaWfB6e1S3MZMPLCWq+TMfVNUlISTZo0ISoqCrHZVgygqmRkZJCUlETXrl1PaR9n9T2o2FkFP3uG\n9lc35VBU5JxVDRjZxD8VM6aeKSoqolWrVhacjJeI0KpVq9M6qz5rz6C+uvNTbp59faW8uMVZ9B/V\n3E81MqZ+s+BkjnW6PxNn5RlU3AfbuLpCcLpr6DaKC8stOBljTB1y1gWoHXN+IubWHt70B4/vYOZ/\netAg7KxrijHGRzIyMujbty99+/alXbt2dOzY0ZsuKSmp0T7uuOMOduzYccIyr776Kh988IEvqgzA\nwYMHCQkJYebMmT7bZ11yVk11VJxVSFiLRt70zjlxdJs0oDarZow5jm3bttGjR4/qC9aCJ598ksaN\nG/Pwww9XyldVVJWgoMD5Z/bll19m7ty5NGjQgMWLz9w0ax6Ph5AQ/9zROd7PRp2c6mjSiFTgXADK\nC4qQRhacjAk4Dz4I69f7dp99+8ILL5z0ZgkJCYwfP55+/fqxbt06Fi1axFNPPcVPP/1EYWEhN910\nE48//jgAw4YN45VXXqFXr15ERkZyzz33sHDhQsLDw5k3bx5t2rThz3/+M5GRkTz44IMMGzaMYcOG\nsWTJErKzs5k9ezZDhw4lPz+fKVOmsG3bNqKjo0lMTGTmzJn07dv3Z/WbM2cOL7/8MhMnTiQ1NZX2\n7dsD8NVXX/GXv/yFsrIy2rZty7fffktubi733Xcf69atA+Dpp5/m6quvJjIykqysLABiY2P57rvv\nmDlzJrfeeitNmjQhLi6OkSNHct111/H73/+eoqIiwsPDefvtt+nWrRsej4dHHnmERYsWERQUxD33\n3MP555/PjBkz+OSTTwBYuHAhs2bN4uOPPz6lb9+pOmsCVFGh8sVGJzhte+MHpNFwP9fIGHM22L59\nO++++y4xMc4/7M888wwtW7bE4/Fw2WWXMXHiRKKjoyttk52dzYgRI3jmmWd46KGHmDVrFtOnT//Z\nvlWV1atXM3/+fJ5++mm+/vprXn75Zdq1a8enn37Khg0b6N+//3HrlZiYSGZmJgMGDOCGG25g7ty5\nPPDAAxw4cIB7772XZcuW0aVLFzIzMwHnzLB169Zs3LgRVfUGpRNJTU1l5cqVBAUFkZ2dzbJlywgJ\nCeHrr7/mz3/+Mx999BGvvfYaKSkpbNiwgeDgYDIzM2nevDn33XcfGRkZtGrVitmzZ3PnnXeebNef\ntrMmQN3SawPQl8+5hu6/+tzf1THGVOUUznTOpPPOO88bnMA5a3nrrbfweDykpKSwdevWnwWoRo0a\nceWVVwIwYMAAli1bdtx9X3fddd4yiYmJACxfvpw//vGPAPTp04eePXsed9vY2FhuuukmACZNmsRv\nfvMbHnjgAVasWMFll11Gly5dAGjpznrz3Xff8cUXXwDO6LgWLVrg8XhO2PYbbrjBe0kzKyuLKVOm\nsGvXrkplvvvuOx588EGCg4MrHW/y5Ml8+OGHTJ48mbi4OObMmXPCY50JZ0WAWjg3l893O6fH1xTG\n2mvXjTE1FhER4V2Oj4/nxRdfZPXq1TRv3pxbb731uM/pNGjQwLscHBxcZSBo2LBhtWWqMmfOHNLT\n03nnnXcASElJYffu3Se1j6CgICqOIzi2LRXb/thjj3HFFVfwm9/8hoSEBMaNG3fCfd95551cf70z\nWvqmm27yBrDaVKO7hSIyTkR2iEiCiPzsPFdEJovIRhHZJCI/ikifCusS3fz1InLSL3nKOqxcdZPz\nwO37Q161V2IYY05ZTk4OTZo0oWnTpqSmpvLNN9/4/BiXXHIJc+fOBWDTpk1s3br1Z2W2bt2Kx+Mh\nOTmZxMREEhMTeeSRR4iNjWXo0KEsXbqUvXv3Angv8Y0ZM4ZXX30VcC4tHj58mKCgIFq0aEF8fDzl\n5eV8/nnVV5eys7Pp2LEjAG+//bY3f8yYMbz++uuUlZVVOt4555xDZGQkzzzzDLfffvvpdcopqjZA\niUgw8CpwJRAN3Cwi0ccU2wOMUNWLgL8CM45Zf5mq9q3JqI2Kysvh4gudN9u+PvhtJv/425PZ3Bhj\nKunfvz/R0dF0796dKVOmcMkll/j8GPfffz/JyclER0fz1FNPER0dTbNmlSewnjNnDtdee22lvOuv\nv545c+bQtm1bXnvtNSZMmECfPn2YPHkyAE888QQHDx6kV69e9O3b13vZ8dlnn+WKK65g6NChdOrU\nqcp6/fGPf+SRRx6hf//+lc66fv3rX9OuXTt69+5Nnz59vMEV4JZbbqFr165ccMEFp90vp6LaYeYi\nMgR4UlWvcNOPAqjq36oo3wLYrKod3XQiEKOq6TWt1JFh5oN7ZLFqe3PubPsVbyWPAz+cYhpjqhdI\nw8z9zePx4PF4CAsLIz4+nrFjxxIfH++3Yd6n45577mHIkCFMnTr1lPdxpoeZdwT2V0gnAYNOUP4u\nYGGFtALfiUgZ8IaqHnt2BYCITAOmAXTu3Jmdm4pZtd2ZGeL177tbcDLGnBXy8vIYPXo0Ho8HVeWN\nN944K4NT3759adGiBS+99JLf6uDTXhORy3AC1LAK2cNUNVlE2gCLRGS7qv5w7LZu4JoBMGBAjP5i\nbAnQkP3vLiW0+2W+rKYxxpwxzZs3Jy4uzt/VOG3rff0s2ymoySCJZOCcCulObl4lItIbmAlMUNWM\nI/mqmux+TQM+BwZWd8CUJCXhQBMeaj6LTrfY807GGFMf1SRArQG6iUhXEWkATALmVywgIp2Bz4Db\nVHVnhfwIEWlyZBkYC2yu7oAH02CKvMv/ftPLLu0ZY0w9Ve0lPlX1iMh9wDdAMDBLVbeIyD3u+teB\nx4FWwL/c6dU97g2wtsDnbl4I8KGqfl3tMRHuvD4HBlZ7smWMMaaOqtE9KFVdACw4Ju/1Cst3A3cf\nZ7vdQJ9j82ui7//ccCqbGWOMqSMCZ1rfChpSTLNubfxdDWPMWeKyyy772UO3L7zwAvfee+8Jt2vc\nuDHgzOIwceLE45YZOXIkx3u7wrHHKigo8KavuuqqGs2VV1N9+/Zl0qRJPtvf2SIgA1RIULlNZ2SM\nqbGbb76Z2NjYSnmxsbHcfPPNNdq+Q4cO3pm7T8WxAWrBggU0b+6bF6hu27aNsrIyli1bRn5+vk/2\neTwnO1VTbQjIABUkgfeOKmNMzTz4IIwc6dvPgw+e+JgTJ07kq6++8r6cMDExkZSUFC699FLvc0n9\n+/fnoosuYt68eT/bPjExkV69egFQWFjIpEmT6NGjB9deey2FhYXecvfeey8xMTH07NmTJ554AoCX\nXnqJlJQULrvsMi67zHkkJioqivR0Z26C559/nl69etGrVy9ecCfSTUxMpEePHvzqV7+iZ8+ejB07\nttJxKpozZw633XYbY8eOrVT3hIQELr/8cvr06UP//v29k8A+++yzXHTRRfTp08c7A3vFs8D09HSi\noqIAZ8qj8ePHM2rUKEaPHn3Cvnr33Xe9s03cdttt5Obm0rVrV0pLSwFnGqmKaV8IyKfHLEAZY05G\ny5YtGThwIAsXLmTChAnExsZy4403IiKEhYXx+eef07RpU9LT0xk8eDDjx49HqrhK89prrxEeHs62\nbdvYuHFjpddl/M///A8tW7akrKyM0aNHs3HjRn73u9/x/PPPs3TpUiIjIyvtKy4ujtmzZ7Nq1SpU\nlUGDBjFixAjv/Hlz5szhzTff5MYbb+TTTz/l1ltv/Vl9PvroIxYtWsT27dt5+eWXueWWWwBntvHp\n06dz7bXXUlRURHl5OQsXLmTevHmsWrWK8PBw77x6J/LTTz+xceNG7ytIjtdXW7du5b//+7/58ccf\niYyMJDMzkyZNmjBy5Ei++uorrrnmGmJjY7nuuusIDQ09mW/dCVmAMsb4lL/etnHkMt+RAPXWW28B\nzsSqf/rTn/jhhx8ICgoiOTmZgwcP0q5du+Pu54cffuB3v/sdAL1796Z3797edXPnzmXGjBl4PB5S\nU1PZunVrpfXHWr58Oddee613VvHrrruOZcuWMX78eLp27ep9iWHF13VUtHbtWiIjI+ncuTMdO3bk\nzjvvJDMzk9DQUJKTk73z+YW5k2h/99133HHHHYSHhwNHX51xImPGjPGWq6qvlixZwg033OANwEfK\n33333fz973/nmmuuYfbs2bz55pvVHu9kBOglPn/XwBhztpkwYQKLFy/mp59+oqCggAEDnDduf/DB\nBxw6dIi4uDjWr19P27Ztj/uKjers2bOH5557jsWLF7Nx40Z+8YtfnNJ+jjjyqg6o+nUdc+bMYfv2\n7URFRXHeeeeRk5PDp59+etLHCgkJoby8HDjxKzlOtq8uueQSEhMT+f777ykrK/NeJvWVwAxQQXYG\nZYw5OY0bN+ayyy7jzjvvrDQ4Ijs7mzZt2hAaGlrpNRZVGT58OB9++CEAmzdvZuPGjYBzjyUiIoJm\nzZpx8OBBFi48OuVokyZNyM3N/dm+Lr30Ur744gsKCgrIz8/n888/59JLL61Re8rLy5k7dy6bNm3y\nvpJj3rx5zJkzhyZNmtCpUyfvCwyLi4spKChgzJgxzJ492ztg48glvqioKO/0SycaDFJVX40aNYqP\nP/6YjIyMSvsFmDJlCrfccgt33HFHjdp1MgIyQNkAPmPMqbj55pvZsGFDpQA1efJk1q5dy0UXXcS7\n775L9+7dT7iPe++9l7y8PHr06MHjjz/uPRPr06cP/fr1o3v37txyyy2VXtUxbdo0xo0b5x0kcUT/\n/v25/fbbGThwIIMGDeLuu++mX79+NWrLsmXL6NixIx06dPDmDR8+nK1bt5Kamsp7773HSy+9RO/e\nvRk6dCgHDhxg3LhxjB8/npiYGPr27ctzzz0HwMMPP8xrr71Gv379vIM3jqeqvurZsyePPfYYI0aM\noE+fPjz00EOVtjl8+HCNR0yejGpft+EP7RtfqKl5O/xdDWNMDdnrNuqvTz75hHnz5vHee+8dd/2Z\nft1GrQsKyPM6Y4wxFd1///0sXLiQBQsWVF/4FFiAMsYYc0pefvnlM7r/gAwFEpC1MsacSCDeLjD+\ndbo/EwEZCoJsnLkxZ5WwsDAyMjIsSBkvVSUjI8P7jNapsEt8xpjT1qlTJ5KSkjh06JC/q2ICSFhY\nGJ06dTrl7QMyQAWHWoQy5mwSGhpK165d/V0NU8fUKBKIyDgR2SEiCSIy/TjrRURectdvFJH+Nd32\neJq1D695C4wxxtRJ1QYoEQkGXgWuBKKBm0Uk+phiVwLd3M804LWT2NYYY4z5mZqcQQ0EElR1t6qW\nALHAhGPKTADeVcdKoLmItK/htsYYY8zP1OQeVEdgf4V0EjCoBmU61nBbAERkGs7ZVySQJyL1fSqJ\nSKDqOUnqD+sH64MjrB8cdaEfutSkUMAMklDVGcAMEVmrqlH+ro+/uf1Q7VQgdZ31g/XBEdYPjvrU\nDzUJUMnAORXSndy8mpQJrcG2xhhjzM/U5B7UGqCbiHQVkQbAJGD+MWXmA1Pc0XyDgWxVTa3htsYY\nY8zPVHsGpaoeEbkP+AYIBmap6hYRucdd/zqwALgKSAAKgDtOtG01h5xxqo2pY6wfHNYP1gdHWD84\n6k0/BOTrNowxxhibssEYY0xAsgBljDEmIAVUgDqVaZECmYicIyJLRWSriGwRkQfc/JYiskhE4t2v\nLSps86jb/h0ickWF/AEissld95KIiJvfUEQ+cvNXiUhUbbezJkQkWETWiciXbro+9kFzEflERLaL\nyDYRGVJP++H37u/DZhGZIyJh9aEfRGSWiKSJyOYKebXSbhGZ6h4jXkSm1k6LfUBVA+KDM4hiF3Au\n0ADYAET7u16n2ab2QH93uQmwE2fKp78D09386cCz7nK02+6GQFe3P4LddauBwYAAC4Er3fzfAK+7\ny5OAj/zd7ir64iHgQ+BLN10f++Ad4G53uQHQvL71A87D+3uARm56LnB7fegHYDjQH9hcIe+Mtxto\nCex2v7Zwl1v4uz9q1Gf+rkCFb9QQ4JsK6UeBR/1dLx+3cR4wBtgBtHfz2gM7jtdmnNGPQ9wy2yvk\n3wy8UbGMuxyC84S5+Lutx7S7E7AYGMXRAFXf+qAZzh9mOSa/vvXDkdllWrp1/BIYW1/6AYiicoA6\n4+2uWMZd9wZws7/7oiafQLrEV9V0SXWCe7rdD1gFtFXnOTGAA0Bbd/lEU0YlHSe/0jaq6gGygVY+\nb8DpeQH4A1BeIa++9UFX4BAw273UOVNEIqhn/aCqycBzwD4gFeeZyW+pZ/1QQW20+6z92xpIAarO\nEpHGwKfAg6qaU3GdOv/S1Nmx/iJyNZCmqnFVlanrfeAKwbm885qq9gPycS7peNWHfnDvsUzACdgd\ngAgRubVimfrQD8dTX9t9IoEUoGoypdJZR0RCcYLTB6r6mZt9UJzZ3nG/prn5VfVBsrt8bH6lbUQk\nBOdSUobvW3LKLgHGi0gizmz2o0TkfepXH4DzX2uSqq5y05/gBKz61g+XA3tU9ZCqlgKfAUOpf/1w\nRG20+6z92xpIAarOTYvkjq55C9imqs9XWDUfODKSZirOvakj+ZPc0Thdcd6vtdq9BJAjIoPdfU45\nZpsj+5oILHH/EwsIqvqoqnZSZwLgSTj1u5V61AcAqnoA2C8iF7pZo4Gt1LN+wLm0N1hEwt36jwa2\nUf/64YjaaPc3wFgRaeGewY518wKfv2+CVfzgTJe0E2fEymP+ro8P2jMM55R9I7De/VyFc114MRAP\nfAe0rLDNY277d+COznHzY4DN7rpXODoLSBjwMc40U6uBc/3d7hP0x0iODpKod30A9AXWuj8PX+CM\nqKqP/fAUsN1tw3s4I9XqfD8Ac3Duu5XinFHfVVvtBu508xOAO/zdFzX92FRHxhhjAlIgXeIzxhhj\nvCxAGWOMCUgWoIwxxgQkC1DGGGMCkgUoY4wxAckClDHGmIBkAcoYY0xA+v+X4JIoNCdRAgAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb0fa22fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy at 0.7401333451271057\n"
     ]
    }
   ],
   "source": [
    "# Change if you have memory restrictions\n",
    "batch_size = 128\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "        if not epoch_i % 20:\n",
    "            print(\"validation accuracy: \", validation_accuracy)\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'b', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/100: 100%|██████████| 1114/1114 [00:00<00:00, 1239.85batches/s]\n",
      "Epoch  2/100: 100%|██████████| 1114/1114 [00:00<00:00, 1269.23batches/s]\n",
      "Epoch  3/100: 100%|██████████| 1114/1114 [00:00<00:00, 1261.68batches/s]\n",
      "Epoch  4/100: 100%|██████████| 1114/1114 [00:00<00:00, 1214.92batches/s]\n",
      "Epoch  5/100: 100%|██████████| 1114/1114 [00:00<00:00, 1262.16batches/s]\n",
      "Epoch  6/100: 100%|██████████| 1114/1114 [00:00<00:00, 1293.26batches/s]\n",
      "Epoch  7/100: 100%|██████████| 1114/1114 [00:00<00:00, 1262.25batches/s]\n",
      "Epoch  8/100: 100%|██████████| 1114/1114 [00:00<00:00, 1269.32batches/s]\n",
      "Epoch  9/100: 100%|██████████| 1114/1114 [00:00<00:00, 1283.26batches/s]\n",
      "Epoch 10/100: 100%|██████████| 1114/1114 [00:00<00:00, 1238.49batches/s]\n",
      "Epoch 11/100: 100%|██████████| 1114/1114 [00:00<00:00, 1261.32batches/s]\n",
      "Epoch 12/100: 100%|██████████| 1114/1114 [00:00<00:00, 1294.10batches/s]\n",
      "Epoch 13/100: 100%|██████████| 1114/1114 [00:00<00:00, 1274.69batches/s]\n",
      "Epoch 14/100: 100%|██████████| 1114/1114 [00:00<00:00, 1266.06batches/s]\n",
      "Epoch 15/100: 100%|██████████| 1114/1114 [00:00<00:00, 1258.48batches/s]\n",
      "Epoch 16/100: 100%|██████████| 1114/1114 [00:00<00:00, 1277.52batches/s]\n",
      "Epoch 17/100: 100%|██████████| 1114/1114 [00:00<00:00, 1259.71batches/s]\n",
      "Epoch 18/100: 100%|██████████| 1114/1114 [00:00<00:00, 1252.59batches/s]\n",
      "Epoch 19/100: 100%|██████████| 1114/1114 [00:00<00:00, 1273.83batches/s]\n",
      "Epoch 20/100: 100%|██████████| 1114/1114 [00:00<00:00, 1272.32batches/s]\n",
      "Epoch 21/100: 100%|██████████| 1114/1114 [00:00<00:00, 1262.61batches/s]\n",
      "Epoch 22/100: 100%|██████████| 1114/1114 [00:00<00:00, 1235.55batches/s]\n",
      "Epoch 23/100: 100%|██████████| 1114/1114 [00:00<00:00, 1254.25batches/s]\n",
      "Epoch 24/100: 100%|██████████| 1114/1114 [00:00<00:00, 1186.39batches/s]\n",
      "Epoch 25/100: 100%|██████████| 1114/1114 [00:00<00:00, 1278.44batches/s]\n",
      "Epoch 26/100: 100%|██████████| 1114/1114 [00:00<00:00, 1257.04batches/s]\n",
      "Epoch 27/100: 100%|██████████| 1114/1114 [00:00<00:00, 1261.38batches/s]\n",
      "Epoch 28/100: 100%|██████████| 1114/1114 [00:00<00:00, 1258.96batches/s]\n",
      "Epoch 29/100: 100%|██████████| 1114/1114 [00:00<00:00, 1260.05batches/s]\n",
      "Epoch 30/100: 100%|██████████| 1114/1114 [00:00<00:00, 1266.01batches/s]\n",
      "Epoch 31/100: 100%|██████████| 1114/1114 [00:00<00:00, 1258.25batches/s]\n",
      "Epoch 32/100: 100%|██████████| 1114/1114 [00:00<00:00, 1239.62batches/s]\n",
      "Epoch 33/100: 100%|██████████| 1114/1114 [00:00<00:00, 1255.38batches/s]\n",
      "Epoch 34/100: 100%|██████████| 1114/1114 [00:00<00:00, 1259.03batches/s]\n",
      "Epoch 35/100: 100%|██████████| 1114/1114 [00:00<00:00, 1242.08batches/s]\n",
      "Epoch 36/100: 100%|██████████| 1114/1114 [00:00<00:00, 1256.92batches/s]\n",
      "Epoch 37/100: 100%|██████████| 1114/1114 [00:00<00:00, 1255.77batches/s]\n",
      "Epoch 38/100: 100%|██████████| 1114/1114 [00:00<00:00, 1229.89batches/s]\n",
      "Epoch 39/100: 100%|██████████| 1114/1114 [00:00<00:00, 1258.88batches/s]\n",
      "Epoch 40/100: 100%|██████████| 1114/1114 [00:00<00:00, 1257.37batches/s]\n",
      "Epoch 41/100: 100%|██████████| 1114/1114 [00:00<00:00, 1236.49batches/s]\n",
      "Epoch 42/100: 100%|██████████| 1114/1114 [00:00<00:00, 1267.99batches/s]\n",
      "Epoch 43/100: 100%|██████████| 1114/1114 [00:00<00:00, 1262.90batches/s]\n",
      "Epoch 44/100: 100%|██████████| 1114/1114 [00:00<00:00, 1259.27batches/s]\n",
      "Epoch 45/100: 100%|██████████| 1114/1114 [00:00<00:00, 1262.48batches/s]\n",
      "Epoch 46/100: 100%|██████████| 1114/1114 [00:00<00:00, 1259.10batches/s]\n",
      "Epoch 47/100: 100%|██████████| 1114/1114 [00:00<00:00, 1256.86batches/s]\n",
      "Epoch 48/100: 100%|██████████| 1114/1114 [00:00<00:00, 1254.89batches/s]\n",
      "Epoch 49/100: 100%|██████████| 1114/1114 [00:00<00:00, 1229.18batches/s]\n",
      "Epoch 50/100: 100%|██████████| 1114/1114 [00:00<00:00, 1249.74batches/s]\n",
      "Epoch 51/100: 100%|██████████| 1114/1114 [00:00<00:00, 1241.29batches/s]\n",
      "Epoch 52/100: 100%|██████████| 1114/1114 [00:00<00:00, 1255.60batches/s]\n",
      "Epoch 53/100: 100%|██████████| 1114/1114 [00:00<00:00, 1240.95batches/s]\n",
      "Epoch 54/100: 100%|██████████| 1114/1114 [00:00<00:00, 1246.21batches/s]\n",
      "Epoch 55/100: 100%|██████████| 1114/1114 [00:01<00:00, 875.12batches/s]\n",
      "Epoch 56/100: 100%|██████████| 1114/1114 [00:01<00:00, 925.98batches/s]\n",
      "Epoch 57/100: 100%|██████████| 1114/1114 [00:01<00:00, 1096.66batches/s]\n",
      "Epoch 58/100: 100%|██████████| 1114/1114 [00:00<00:00, 1121.93batches/s]\n",
      "Epoch 59/100: 100%|██████████| 1114/1114 [00:00<00:00, 1221.97batches/s]\n",
      "Epoch 60/100: 100%|██████████| 1114/1114 [00:00<00:00, 1317.53batches/s]\n",
      "Epoch 61/100: 100%|██████████| 1114/1114 [00:00<00:00, 1368.87batches/s]\n",
      "Epoch 62/100: 100%|██████████| 1114/1114 [00:00<00:00, 1248.22batches/s]\n",
      "Epoch 63/100: 100%|██████████| 1114/1114 [00:00<00:00, 1248.11batches/s]\n",
      "Epoch 64/100: 100%|██████████| 1114/1114 [00:00<00:00, 1248.57batches/s]\n",
      "Epoch 65/100: 100%|██████████| 1114/1114 [00:00<00:00, 1352.68batches/s]\n",
      "Epoch 66/100: 100%|██████████| 1114/1114 [00:00<00:00, 1297.92batches/s]\n",
      "Epoch 67/100: 100%|██████████| 1114/1114 [00:00<00:00, 1206.04batches/s]\n",
      "Epoch 68/100: 100%|██████████| 1114/1114 [00:01<00:00, 933.31batches/s]\n",
      "Epoch 69/100: 100%|██████████| 1114/1114 [00:01<00:00, 1027.35batches/s]\n",
      "Epoch 70/100: 100%|██████████| 1114/1114 [00:01<00:00, 1111.51batches/s]\n",
      "Epoch 71/100: 100%|██████████| 1114/1114 [00:00<00:00, 1122.24batches/s]\n",
      "Epoch 72/100: 100%|██████████| 1114/1114 [00:00<00:00, 1152.93batches/s]\n",
      "Epoch 73/100: 100%|██████████| 1114/1114 [00:01<00:00, 1028.28batches/s]\n",
      "Epoch 74/100: 100%|██████████| 1114/1114 [00:00<00:00, 1148.75batches/s]\n",
      "Epoch 75/100: 100%|██████████| 1114/1114 [00:00<00:00, 1114.53batches/s]\n",
      "Epoch 76/100: 100%|██████████| 1114/1114 [00:00<00:00, 1153.24batches/s]\n",
      "Epoch 77/100: 100%|██████████| 1114/1114 [00:00<00:00, 1264.85batches/s]\n",
      "Epoch 78/100: 100%|██████████| 1114/1114 [00:00<00:00, 1267.05batches/s]\n",
      "Epoch 79/100: 100%|██████████| 1114/1114 [00:00<00:00, 1328.77batches/s]\n",
      "Epoch 80/100: 100%|██████████| 1114/1114 [00:00<00:00, 1314.84batches/s]\n",
      "Epoch 81/100: 100%|██████████| 1114/1114 [00:00<00:00, 1284.16batches/s]\n",
      "Epoch 82/100: 100%|██████████| 1114/1114 [00:00<00:00, 1288.66batches/s]\n",
      "Epoch 83/100: 100%|██████████| 1114/1114 [00:00<00:00, 1271.85batches/s]\n",
      "Epoch 84/100: 100%|██████████| 1114/1114 [00:00<00:00, 1287.47batches/s]\n",
      "Epoch 85/100: 100%|██████████| 1114/1114 [00:00<00:00, 1294.35batches/s]\n",
      "Epoch 86/100: 100%|██████████| 1114/1114 [00:00<00:00, 1282.56batches/s]\n",
      "Epoch 87/100: 100%|██████████| 1114/1114 [00:00<00:00, 1335.23batches/s]\n",
      "Epoch 88/100: 100%|██████████| 1114/1114 [00:00<00:00, 1323.21batches/s]\n",
      "Epoch 89/100: 100%|██████████| 1114/1114 [00:00<00:00, 1171.67batches/s]\n",
      "Epoch 90/100: 100%|██████████| 1114/1114 [00:00<00:00, 1277.50batches/s]\n",
      "Epoch 91/100: 100%|██████████| 1114/1114 [00:00<00:00, 1313.16batches/s]\n",
      "Epoch 92/100: 100%|██████████| 1114/1114 [00:00<00:00, 1302.40batches/s]\n",
      "Epoch 93/100: 100%|██████████| 1114/1114 [00:00<00:00, 1251.05batches/s]\n",
      "Epoch 94/100: 100%|██████████| 1114/1114 [00:00<00:00, 1322.77batches/s]\n",
      "Epoch 95/100: 100%|██████████| 1114/1114 [00:00<00:00, 1338.09batches/s]\n",
      "Epoch 96/100: 100%|██████████| 1114/1114 [00:00<00:00, 1267.09batches/s]\n",
      "Epoch 97/100: 100%|██████████| 1114/1114 [00:00<00:00, 1279.97batches/s]\n",
      "Epoch 98/100: 100%|██████████| 1114/1114 [00:00<00:00, 1272.99batches/s]\n",
      "Epoch 99/100: 100%|██████████| 1114/1114 [00:00<00:00, 1308.04batches/s]\n",
      "Epoch 100/100: 100%|██████████| 1114/1114 [00:00<00:00, 1303.39batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is 0.8195000290870667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The accuracy measured against the test set\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer\n",
    "            _ = session.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Check accuracy against Test data\n",
    "        test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "\n",
    "print('Test Accuracy is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
